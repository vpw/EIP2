{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNST_CIFAR10_AUG.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vpw/EIP2/blob/master/Session4/DNST_CIFAR10_AUG-BC-100-12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "outputId": "89eb1f56-aa53-4750-a009-aa116b57be69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import VarianceScaling\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64 # or 128\n",
        "num_classes = 10\n",
        "epochs = 50 # increase to 250\n",
        "depth = 100 # total num layers - 40 for\tDN, 100 for DN BC\n",
        "k = 12 # growth rate\n",
        "compression = 0.5 # reduction\n",
        "dropout_rate = 0.2 # None for augmented  # 0.2 for non augmented\n",
        "\n",
        "learning_rate = 0.1 # initial\n",
        "weight_decay = 1e-4 # DCNNN paper\n",
        "momentum = 0.9 # Nesterov\n",
        "\n",
        "num_blocks = 3 # number of dense blocks in the network\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "outputId": "cc0a1693-5678-49fe-b422-83a514fed93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# convert to float\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalize - TODO check channel mean and std normalization later\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 60s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hwe3nJJWv7Bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_layers, num_filter, growth_rate, dropout_rate = None):\n",
        "    global compression\n",
        "    global init_mrsa\n",
        "    global weight_decay\n",
        "    temp = input\n",
        "    for _ in range(num_layers):\n",
        "        BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay/2),\n",
        "                                       beta_regularizer=l2(weight_decay/2))(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        # 1x1 conv - bottleneck layer\n",
        "        Conv2D_1_1 = Conv2D(int(4*growth_rate),\n",
        "            (1,1),\n",
        "            use_bias=False,\n",
        "            padding='same',\n",
        "            kernel_initializer=init_mrsa,\n",
        "            kernel_regularizer=l2(weight_decay/2))(relu)\n",
        "        # 3x3 conv\n",
        "        Conv2D_3_3 = Conv2D(int(growth_rate),\n",
        "            (3,3), \n",
        "            use_bias=False, \n",
        "            padding='same',\n",
        "            kernel_initializer=init_mrsa,\n",
        "            kernel_regularizer=l2(weight_decay/2))(Conv2D_1_1)\n",
        "        if dropout_rate>0:\n",
        "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        # concat outputs\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        num_filter += growth_rate\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp, num_filter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter, dropout_rate = None):\n",
        "    global compression\n",
        "    global init_mrsa\n",
        "    global weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay/2), \n",
        "                                beta_regularizer=l2(weight_decay/2))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), \n",
        "        kernel_initializer=init_mrsa,\n",
        "        use_bias=False, \n",
        "        padding='same',\n",
        "        kernel_regularizer=l2(weight_decay/2))(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2), strides=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg, int(num_filter*compression)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input, size):\n",
        "    global compression\n",
        "    global weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay/2), \n",
        "                                beta_regularizer=l2(weight_decay/2))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    #AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    # try global lavg pooling\n",
        "    AvgPooling = AveragePooling2D(pool_size=(size,size))(relu)\n",
        "    # try 2x2 with 2x2 stride - gives 4x4x27\n",
        "    #AvgPooling = AveragePooling2D(pool_size=(2,2), strides=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "20a34f91-222e-444f-8c38-1fec64489c38"
      },
      "cell_type": "code",
      "source": [
        "# num layers in each block\n",
        "num_layers = int((depth - 4)/num_blocks) \n",
        "\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "init_mrsa = VarianceScaling(2.0) # mode = FAN_IN, distribution=normal, to get MRSA init\n",
        "# https://www.tensorflow.org/api_docs/python/tf/contrib/layers/variance_scaling_initializer\n",
        "# https://medium.com/intuitionmachine/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504\n",
        "\n",
        "# initial number of filters - output of 1st layer is 2 * growth rate\n",
        "num_filter = k * 2 \n",
        "\n",
        "output = Conv2D(num_filter,  \n",
        "                (3,3), \n",
        "                kernel_initializer=init_mrsa,\n",
        "                use_bias=False,\n",
        "                padding='same',\n",
        "                kernel_regularizer=l2(weight_decay/2))(input) # https://bbabenko.github.io/weight-decay/\n",
        "#32x32, 24\n",
        "\n",
        "print (f'num_layers {num_layers}')\n",
        "for block in range(num_blocks): \n",
        "    # num_layers/2 due to bottleneck net - 1 1x1 and 1 3x3 in each step\n",
        "    print (f'DN: block {block} DB : in num_filter {num_filter}')\n",
        "    output, num_filter = add_denseblock(output, int(num_layers/2), num_filter, k, dropout_rate)\n",
        "    print (f'DN: block {block} DB : out num_filter {num_filter}')\n",
        "#32x32, 24+12=36, 16x16x18+12=30, 8x8x15+12=27\n",
        "    if (block != (num_blocks-1)):\n",
        "        print (f'DN: block {block} TR : in num_filter {num_filter}')\n",
        "        output, num_filter = add_transition(output, num_filter, dropout_rate)\n",
        "        print (f'DN: block {block} TR : out num_filter {num_filter}')\n",
        "#32x32, 16x16x36/2=18, 8x8x30/2=15, \n",
        "\n",
        "#First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "#First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "#Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "#Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "#Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "#Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "#Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "#\n",
        "# 8x8x27\n",
        "output = output_layer(output, 8)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_layers 32\n",
            "DN: block 0 DB : in num_filter 24\n",
            "DN: block 0 DB : out num_filter 216\n",
            "DN: block 0 TR : in num_filter 216\n",
            "DN: block 0 TR : out num_filter 108\n",
            "DN: block 1 DB : in num_filter 108\n",
            "DN: block 1 DB : out num_filter 300\n",
            "DN: block 1 TR : in num_filter 300\n",
            "DN: block 1 TR : out num_filter 150\n",
            "DN: block 2 DB : in num_filter 150\n",
            "DN: block 2 DB : out num_filter 342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "outputId": "a1b01747-c9b9-45f6-d145-e041d55fc271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11322
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 32, 32, 24)   648         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 32, 32, 24)   96          conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 32, 32, 24)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 32, 32, 48)   1152        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, 32, 32, 12)   0           conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 32, 32, 36)   0           conv2d_200[0][0]                 \n",
            "                                                                 dropout_101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 32, 32, 36)   144         concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 32, 32, 36)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 32, 32, 48)   1728        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, 32, 32, 12)   0           conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 32, 32, 48)   0           concatenate_97[0][0]             \n",
            "                                                                 dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 48)   192         concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 48)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 32, 32, 48)   2304        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 32, 32, 12)   0           conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 32, 32, 60)   0           concatenate_98[0][0]             \n",
            "                                                                 dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 60)   240         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 32, 32, 60)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 32, 32, 48)   2880        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 32, 32, 12)   0           conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 32, 32, 72)   0           concatenate_99[0][0]             \n",
            "                                                                 dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 72)   288         concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 32, 32, 72)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 32, 32, 48)   3456        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 32, 32, 12)   0           conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 32, 32, 84)   0           concatenate_100[0][0]            \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 84)   336         concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 32, 32, 84)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 32, 32, 48)   4032        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 32, 32, 12)   0           conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 32, 32, 96)   0           concatenate_101[0][0]            \n",
            "                                                                 dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 96)   384         concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 32, 32, 96)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 32, 32, 48)   4608        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 32, 32, 12)   0           conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 32, 32, 108)  0           concatenate_102[0][0]            \n",
            "                                                                 dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 108)  432         concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 32, 32, 108)  0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 32, 32, 48)   5184        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 32, 32, 12)   0           conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 32, 32, 120)  0           concatenate_103[0][0]            \n",
            "                                                                 dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 120)  480         concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 32, 32, 120)  0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 32, 32, 48)   5760        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 32, 32, 12)   0           conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 32, 32, 132)  0           concatenate_104[0][0]            \n",
            "                                                                 dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 132)  528         concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 32, 32, 132)  0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 32, 32, 48)   6336        activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 32, 32, 12)   0           conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 32, 32, 144)  0           concatenate_105[0][0]            \n",
            "                                                                 dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 32, 32, 144)  576         concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 32, 32, 144)  0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 32, 32, 48)   6912        activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 32, 32, 12)   0           conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 32, 32, 156)  0           concatenate_106[0][0]            \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 32, 32, 156)  624         concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 32, 32, 156)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 32, 32, 48)   7488        activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 32, 32, 12)   0           conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 32, 32, 168)  0           concatenate_107[0][0]            \n",
            "                                                                 dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 32, 32, 168)  672         concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 32, 32, 168)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 32, 32, 48)   8064        activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 32, 32, 12)   0           conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 32, 32, 180)  0           concatenate_108[0][0]            \n",
            "                                                                 dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 32, 32, 180)  720         concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 32, 32, 180)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 32, 32, 48)   8640        activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 32, 32, 12)   0           conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 32, 32, 192)  0           concatenate_109[0][0]            \n",
            "                                                                 dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 32, 32, 192)  768         concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 32, 32, 192)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 32, 32, 48)   9216        activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 32, 32, 12)   0           conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 32, 32, 204)  0           concatenate_110[0][0]            \n",
            "                                                                 dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 32, 32, 204)  816         concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 32, 32, 204)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 32, 32, 48)   9792        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 32, 32, 12)   5184        conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 32, 32, 12)   0           conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 32, 32, 216)  0           concatenate_111[0][0]            \n",
            "                                                                 dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 32, 32, 216)  864         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 32, 32, 216)  0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 32, 32, 108)  23328       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 32, 32, 108)  0           conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 16, 16, 108)  0           dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 108)  432         average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 108)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 16, 16, 48)   5184        activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 16, 16, 12)   0           conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 16, 16, 120)  0           average_pooling2d_7[0][0]        \n",
            "                                                                 dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 120)  480         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 120)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 16, 16, 48)   5760        activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 16, 16, 12)   0           conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 16, 16, 132)  0           concatenate_113[0][0]            \n",
            "                                                                 dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 132)  528         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 132)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 16, 16, 48)   6336        activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 16, 16, 12)   0           conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 16, 16, 144)  0           concatenate_114[0][0]            \n",
            "                                                                 dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 144)  576         concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 144)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 16, 16, 48)   6912        activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 16, 16, 12)   0           conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 16, 16, 156)  0           concatenate_115[0][0]            \n",
            "                                                                 dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 16, 16, 156)  624         concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 16, 16, 156)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 16, 16, 48)   7488        activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 16, 16, 12)   0           conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 16, 16, 168)  0           concatenate_116[0][0]            \n",
            "                                                                 dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 168)  672         concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 16, 16, 168)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 16, 16, 48)   8064        activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 16, 16, 12)   0           conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 16, 16, 180)  0           concatenate_117[0][0]            \n",
            "                                                                 dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 180)  720         concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 16, 16, 180)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 16, 16, 48)   8640        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 16, 16, 12)   0           conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 16, 16, 192)  0           concatenate_118[0][0]            \n",
            "                                                                 dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 16, 16, 192)  768         concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 16, 16, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 16, 16, 48)   9216        activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 16, 16, 12)   0           conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 16, 16, 204)  0           concatenate_119[0][0]            \n",
            "                                                                 dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 204)  816         concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 16, 16, 204)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 16, 16, 48)   9792        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 16, 16, 12)   0           conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 16, 16, 216)  0           concatenate_120[0][0]            \n",
            "                                                                 dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 16, 16, 216)  864         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 16, 16, 216)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 16, 16, 48)   10368       activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 16, 16, 12)   0           conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 16, 16, 228)  0           concatenate_121[0][0]            \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 16, 16, 228)  912         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 16, 16, 228)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 16, 16, 48)   10944       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 16, 16, 12)   0           conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 16, 16, 240)  0           concatenate_122[0][0]            \n",
            "                                                                 dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 16, 16, 240)  960         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 16, 16, 240)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 16, 16, 48)   11520       activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 16, 16, 12)   0           conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 16, 16, 252)  0           concatenate_123[0][0]            \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 16, 16, 252)  1008        concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 16, 16, 252)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 16, 16, 48)   12096       activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 16, 16, 12)   0           conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 16, 16, 264)  0           concatenate_124[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 16, 16, 264)  1056        concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 16, 16, 264)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 16, 16, 48)   12672       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 16, 16, 12)   0           conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 16, 16, 276)  0           concatenate_125[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 16, 16, 276)  1104        concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 16, 16, 276)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 16, 16, 48)   13248       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 16, 16, 12)   0           conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 16, 16, 288)  0           concatenate_126[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 16, 16, 288)  1152        concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 16, 16, 288)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 16, 16, 48)   13824       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 16, 16, 12)   5184        conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 16, 16, 12)   0           conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 16, 16, 300)  0           concatenate_127[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 16, 16, 300)  1200        concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 16, 16, 300)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 16, 16, 150)  45000       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 16, 16, 150)  0           conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 150)    0           dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 150)    600         average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 150)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 8, 8, 48)     7200        activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 8, 8, 12)     0           conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 8, 8, 162)    0           average_pooling2d_8[0][0]        \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 162)    648         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 162)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 8, 8, 48)     7776        activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 8, 8, 12)     0           conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 8, 8, 174)    0           concatenate_129[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 174)    696         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 174)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 8, 8, 48)     8352        activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 8, 8, 12)     0           conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 8, 8, 186)    0           concatenate_130[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 8, 8, 186)    744         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 186)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 8, 8, 48)     8928        activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 8, 8, 12)     0           conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 8, 8, 198)    0           concatenate_131[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 8, 8, 198)    792         concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 198)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 48)     9504        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 8, 8, 12)     0           conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 8, 8, 210)    0           concatenate_132[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 8, 8, 210)    840         concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 8, 8, 210)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 8, 8, 48)     10080       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 8, 8, 12)     0           conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 8, 8, 222)    0           concatenate_133[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 8, 8, 222)    888         concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 8, 8, 222)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 48)     10656       activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 8, 8, 12)     0           conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 8, 8, 234)    0           concatenate_134[0][0]            \n",
            "                                                                 dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 8, 8, 234)    936         concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 8, 8, 234)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 48)     11232       activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 8, 8, 12)     0           conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 8, 8, 246)    0           concatenate_135[0][0]            \n",
            "                                                                 dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 8, 8, 246)    984         concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 8, 8, 246)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 8, 8, 48)     11808       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 8, 8, 12)     0           conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 8, 8, 258)    0           concatenate_136[0][0]            \n",
            "                                                                 dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 8, 8, 258)    1032        concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 8, 8, 258)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 8, 8, 48)     12384       activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 8, 8, 12)     0           conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 8, 8, 270)    0           concatenate_137[0][0]            \n",
            "                                                                 dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 8, 8, 270)    1080        concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 8, 8, 270)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 8, 8, 48)     12960       activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 8, 8, 12)     0           conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 8, 8, 282)    0           concatenate_138[0][0]            \n",
            "                                                                 dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 8, 8, 282)    1128        concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 8, 8, 282)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 8, 8, 48)     13536       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_146 (Dropout)           (None, 8, 8, 12)     0           conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 8, 8, 294)    0           concatenate_139[0][0]            \n",
            "                                                                 dropout_146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 8, 8, 294)    1176        concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 8, 8, 294)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 8, 8, 48)     14112       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_147 (Dropout)           (None, 8, 8, 12)     0           conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 8, 8, 306)    0           concatenate_140[0][0]            \n",
            "                                                                 dropout_147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 8, 8, 306)    1224        concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 8, 8, 306)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 8, 8, 48)     14688       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_148 (Dropout)           (None, 8, 8, 12)     0           conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 8, 8, 318)    0           concatenate_141[0][0]            \n",
            "                                                                 dropout_148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 8, 8, 318)    1272        concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 8, 8, 318)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 8, 8, 48)     15264       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_149 (Dropout)           (None, 8, 8, 12)     0           conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 8, 8, 330)    0           concatenate_142[0][0]            \n",
            "                                                                 dropout_149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 8, 8, 330)    1320        concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 8, 8, 330)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 8, 8, 48)     15840       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 8, 8, 12)     5184        conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_150 (Dropout)           (None, 8, 8, 12)     0           conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 8, 8, 342)    0           concatenate_143[0][0]            \n",
            "                                                                 dropout_150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 8, 8, 342)    1368        concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 8, 8, 342)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 1, 1, 342)    0           activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 342)          0           average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           3430        flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 783,934\n",
            "Trainable params: 764,554\n",
            "Non-trainable params: 19,380\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GnNypE4IbUbZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "sgd = SGD(lr=learning_rate,momentum=momentum, decay=0.0, nesterov=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "#              optimizer=Adam(),\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "outputId": "ac9e4285-f7ea-4752-f821-aa76a058f70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1788
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 355s 7ms/step - loss: 1.9812 - acc: 0.5309 - val_loss: 2.4337 - val_acc: 0.4832\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 1.4791 - acc: 0.6947 - val_loss: 1.7511 - val_acc: 0.6340\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 1.2615 - acc: 0.7559 - val_loss: 1.7131 - val_acc: 0.6457\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 1.1185 - acc: 0.7915 - val_loss: 1.3804 - val_acc: 0.7301\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 1.0193 - acc: 0.8147 - val_loss: 1.0259 - val_acc: 0.8057\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.9367 - acc: 0.8317 - val_loss: 1.1921 - val_acc: 0.7488\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.8715 - acc: 0.8444 - val_loss: 1.0856 - val_acc: 0.7817\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.8201 - acc: 0.8543 - val_loss: 1.2725 - val_acc: 0.7280\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.7754 - acc: 0.8631 - val_loss: 1.0105 - val_acc: 0.7834\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.7301 - acc: 0.8701 - val_loss: 1.0414 - val_acc: 0.7936\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.6971 - acc: 0.8783 - val_loss: 0.9278 - val_acc: 0.8161\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.6712 - acc: 0.8810 - val_loss: 0.8963 - val_acc: 0.8138\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.6387 - acc: 0.8886 - val_loss: 0.8123 - val_acc: 0.8434\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.6138 - acc: 0.8930 - val_loss: 0.9469 - val_acc: 0.8032\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 332s 7ms/step - loss: 0.5893 - acc: 0.8987 - val_loss: 0.9584 - val_acc: 0.8074\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.5693 - acc: 0.9020 - val_loss: 1.1818 - val_acc: 0.7599\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.5508 - acc: 0.9054 - val_loss: 0.7973 - val_acc: 0.8317\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.5343 - acc: 0.9089 - val_loss: 0.7019 - val_acc: 0.8678\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.5170 - acc: 0.9131 - val_loss: 0.7593 - val_acc: 0.8481\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 332s 7ms/step - loss: 0.5036 - acc: 0.9159 - val_loss: 0.7193 - val_acc: 0.8564\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 332s 7ms/step - loss: 0.4924 - acc: 0.9169 - val_loss: 0.7634 - val_acc: 0.8477\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4766 - acc: 0.9211 - val_loss: 0.9109 - val_acc: 0.8142\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4672 - acc: 0.9231 - val_loss: 0.9364 - val_acc: 0.8002\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4616 - acc: 0.9233 - val_loss: 0.6908 - val_acc: 0.8621\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4477 - acc: 0.9266 - val_loss: 0.7613 - val_acc: 0.8514\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4350 - acc: 0.9302 - val_loss: 0.6890 - val_acc: 0.8609\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4280 - acc: 0.9306 - val_loss: 0.6790 - val_acc: 0.8660\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4138 - acc: 0.9350 - val_loss: 0.7287 - val_acc: 0.8591\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4086 - acc: 0.9364 - val_loss: 0.7563 - val_acc: 0.8492\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.4038 - acc: 0.9363 - val_loss: 0.9011 - val_acc: 0.8208\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3907 - acc: 0.9391 - val_loss: 0.6925 - val_acc: 0.8645\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3859 - acc: 0.9402 - val_loss: 0.7268 - val_acc: 0.8518\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3868 - acc: 0.9385 - val_loss: 0.7403 - val_acc: 0.8604\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3775 - acc: 0.9418 - val_loss: 0.6083 - val_acc: 0.8787\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3711 - acc: 0.9425 - val_loss: 0.8861 - val_acc: 0.8296\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3597 - acc: 0.9478 - val_loss: 0.7073 - val_acc: 0.8583\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3530 - acc: 0.9480 - val_loss: 0.6782 - val_acc: 0.8670\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3495 - acc: 0.9479 - val_loss: 0.6367 - val_acc: 0.8757\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3472 - acc: 0.9479 - val_loss: 0.6547 - val_acc: 0.8702\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3444 - acc: 0.9485 - val_loss: 0.6346 - val_acc: 0.8782\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3369 - acc: 0.9505 - val_loss: 0.6334 - val_acc: 0.8775\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3297 - acc: 0.9528 - val_loss: 0.7349 - val_acc: 0.8570\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3297 - acc: 0.9523 - val_loss: 0.6651 - val_acc: 0.8696\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3227 - acc: 0.9534 - val_loss: 0.6710 - val_acc: 0.8671\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3213 - acc: 0.9545 - val_loss: 0.5940 - val_acc: 0.8805\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3153 - acc: 0.9551 - val_loss: 0.6034 - val_acc: 0.8772\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3101 - acc: 0.9572 - val_loss: 0.5946 - val_acc: 0.8819\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3048 - acc: 0.9589 - val_loss: 0.5692 - val_acc: 0.8883\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3049 - acc: 0.9582 - val_loss: 0.6183 - val_acc: 0.8811\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 331s 7ms/step - loss: 0.3014 - acc: 0.9592 - val_loss: 0.6091 - val_acc: 0.8761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe424b19e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "dAHaMMbXlOyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8106d9d1-1fe9-4dc9-c89d-a0c2fd623055"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h-Mf7JGRlxz8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath=\"/content/gdrive/My Drive/EIP2/Session4/1/DCNN_1st_best.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "402zzOr-rKdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a09713e-3f62-43df-cb80-d20280bf0ff4"
      },
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/gdrive/My\\ Drive/foo.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ksmlBSw9mN6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5de9405f-5243-4154-ae98-ca6eb96a2ac3"
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "mcp = ModelCheckpoint(filepath, verbose=1, save_best_only=True)\n",
        "\n",
        "cb_list = [mcp]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GV59a03fhNfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "99da5881-d517-4e51-8041-68404519a476"
      },
      "cell_type": "code",
      "source": [
        "# try next 50 epochs with same base LR, and reduceLROnPlateau\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "rlr = ReduceLROnPlateau(patience=6, verbose=1, min_lr=0.001)\n",
        "\n",
        "cb_list.append(rlr)\n",
        "\n",
        "epochs=50\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=cb_list)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2234af73a8c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     10\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "g3jAXLRgm2n-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# try next 50 with LR/10 \n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=cb_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "outputId": "a0345aa5-79ff-4e56-eb94-50437b43c4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 13s 1ms/step\n",
            "Test loss: 0.7949684534072876\n",
            "Test accuracy: 0.7609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "outputId": "92df862c-76a7-4a02-9533-6c164bc5984d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}